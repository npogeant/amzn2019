# -*- coding: utf-8 -*-
"""Sentiment script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KAjLBM6McU-FZxQQk4KEd3ST9XNOsqiG
"""

!pip install transformers

import numpy as np
from google.colab import files

# Commented out IPython magic to ensure Python compatibility.
!pip install ipython-autotime
# %load_ext autotime
! pip install nltk

# import pandas as pd
import pandas as pd
import re

import re
import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk import word_tokenize
stop = stopwords.words('english')
from collections import Counter
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

df = pd.read_json("/content/drive/MyDrive/Data Science/Amazon Tweets/AMZNdec2019.json",  lines=True)

df = df[df['lang'].isin(['en'])]

#Function that will remove links, special characters, digits, emojis, spaces, single letters
def cleaning_tweets(text): 
    
    text = str(text)
    
    text = re.sub(r'http\S+', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    
    text = text.split()
    
    return text

df["content_modified"] = df['content'].apply(lambda x: cleaning_tweets(x))
df["content_modified"] = df["content_modified"].apply(lambda x: ' '.join([word for word in x if word not in (stop)]))

df.drop(columns=['url', 'content', 'renderedContent', 'id', 'user', 'outlinks', 
                   'outlinksss', 'tcooutlinks', 'tcooutlinksss', 'replyCount', 'retweetCount', 'likeCount', 'quoteCount', "lang", "conversationId", "source", "media", "retweetedTweet", "quotedTweet", "mentionedUsers"], inplace=True)

df.sample(5)

from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import pipeline

model_name = "ProsusAI/finbert"
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)

df = (
    df
    .assign(sentiment = lambda x: x['content_modified'].apply(lambda s: classifier(s)))
    .assign(
         label = lambda x: x['sentiment'].apply(lambda s: (s[0]['label'])),
         score = lambda x: x['sentiment'].apply(lambda s: (s[0]['score']))
    )
)

df["label"].value_counts()

df.to_json("df.json")
files.download('df.json')